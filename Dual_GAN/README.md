
# Dual GAN

Joint BVP and Noise Modeling for Remote Physiological Measurement

Through Dual-GAN architecture we not only model BVP predictor but also explicitly model noise distribution via adversarial learning, and thus can obtain more robustness BVP representation against unseen noises.




## Abstract

Remote photoplethysmography (rPPG) based physiolog
ical measurement has great application values in health
 monitoring, emotion analysis, etc. Existing methods mainly
 focus on how to enhance or extract the very weak blood
 volume pulse (BVP) signals from face videos, but seldom
 explicitly model the noises that dominate face video con
tent. Thus, they may suffer from poor generalization abil
ity in unseen scenarios. Dual GAN proposes a novel ad
versarial learning approach for rPPG based physiological
 measurement by using Dual Generative Adversarial Net
works (Dual-GAN) to model the BVP predictor and noise
 distribution jointly. The BVP-GAN aims to learn a noise
resistant mapping from input to ground-truth BVP, and the
 Noise-GAN aims to learn the noise distribution. The two
 GANs can promote each other’s capability, leading to im
proved feature disentanglement between BVP and noises.
 Besides, a plug-and-play block named ROI alignment and
 fusion (ROI-AF) block is proposed to alleviate the inconsis
tencies between different ROIs and exploit informative fea
tures from a wider receptive field in terms of ROIs. In com
parison to state-of-the-art methods, our approach achieves
 better performance in heart rate, heart rate variability, and
 respiration frequency estimation from face videos.

 ## Install and compile the prerequisites

•Python 3.9

•PyTorch = 2.3.0+cu121

•NVIDIA GPU + CUDA

•torchvision = 0.18.0+cu121

•Python packages: numpy,opencv-python,matplotlib

## Training Process
We trained the Dual GAN model only on UBFC Dataset. The UBFC Dataset contains the video file and its corresponding ground truth ppg data. The ground truth file contain three rows, 1st row conatin the ppg signal, 2nd row contain the HR, 3rd row contain timestamp of corresponding ppg signal.

Each of the video of UBFC has been converted into STMap on paramhimalaya using the STMap_generator_lib folder in backend_driver_ass with minor changes.

The Model has been trained for 512 epochs on paramhimalaya.

## Instruction to Execute the Dual GAN Code

backend_driver_ass contain 2 types of execution file for testing

1) Testing without generating STMap (recommended): As the video size of each subject is more than 1.5 GB so we uploaded STMap (Spatio Temporal Map, a preliminary representation of video file generated by ourselfs) of one of the subject and its corresponding ground truth data. This can be executed as follow:

(i) Go to backend_driver_ass --> model_folder --> testing_code2_without_gen_STMap.py

(ii) Change the directory of backend_driver_ass_path according to backend_driver_ass folder path

(ii) Run the testing_code2_without_gen_STMap.py

This code will take input of STMap of one of the subject(video_5x5_ori.png) and ground_truth.txt from the 'backend_driver_ass/SAMPLE_DATA' and predict the rppg using video_5x5_ori.png and plot and save the predicted and ground truth graph.

2) Testing via generating STMap: Executor need to add the 'vid.avi' and its corresponding 'ground_truth.txt' file in 
 'backend_driver_ass/SAMPLE_DATA' folder. 
 Change the sample_location and OUTPUT_DIR in "backend_driver_ass/directory.py" according to the location of folders "backend_driver_ass/SAMPLE_DATA" and "backend_driver_ass/SAMPLE_DATA/cache" respectively.

 This can be executed as follows:

 i) Run the integrate1.py file in backend_driver_ass folder.

 
 ## Citation 

 @article{title={ Dual-GAN: Joint BVP and Noise Modeling for Remote Physiological
 Measurement},
  author={ Hao Lu, Hu Han, S. Kevin Zhou},
  year={2021}
}